<h3>Experiment 8: Heuristics and Biases That Do Associate With Cognitive Ability</h3><br/><p class="body-paragraph" data-auto="body_paragraph">In the previous seven experiments, we have shown that a wide variety of <strong data-auto="strong_text">cognitive</strong> <strong data-auto="strong_text">biases</strong> are dissociated from <strong data-auto="strong_text">cognitive ability</strong>. However, we do not mean to imply that effects from the heuristics and <strong data-auto="strong_text">biases</strong> literature are invariably independent of intelligence. To the contrary, in the introduction we mentioned several <strong data-auto="strong_text">biases</strong> in which there has been at least some suggestion of an association. In this experiment, we collected together several such effects, including several well-known logical reasoning and probabilistic reasoning tasks and <strong data-auto="strong_text">biases</strong>.</p> <h4>Method and Results</h4><p class="body-paragraph" data-auto="body_paragraph"><strong>Probabilistic Reasoning: Denominator Neglect</strong></p><p class="body-paragraph" data-auto="body_paragraph">This probabilistic reasoning task was a marble game that was modeled on a task introduced by Kirkpatrick and Epstein (1992; see also Denes-Raj &amp; Epstein, 1994; Pacini &amp; Epstein, 1999). The task read as follows:
<blockquote>Assume that you are presented with two trays of black and white marbles, a large tray that contains 100 marbles and a small tray that contains 10 marbles. The marbles are spread in a single layer in each tray. You must draw out one marble (without peeking, of course) from either tray. If you draw a black marble you win $2. Consider a condition in which the small tray contains 1 black marble and 9 white marbles, and the large tray contains 8 black marbles and 92 white marbles [a visual of each tray was presented to participants]. From which tray would you prefer to select a marble in a real situation?: ____ the small tray ____ the large tray.</blockquote></p><p class="body-paragraph" data-auto="body_paragraph">The normative response is of course to select the small tray, because it has the highest probability (10% vs. 8%) of yielding a winning black marble. Nonetheless, Epstein and colleagues (see also Klaczynski, 2001; Kokis et al., 2002) have found that a significant minority of participants choose the large tray. Kokis et al. (2002) found, in a sample of children, a significant .28 correlation between <strong data-auto="strong_text">cognitive ability</strong> and the tendency to choose the small tray. However, little is known about the nature of the correlation in an adult sample.</p><p class="body-paragraph" data-auto="body_paragraph">The 819 participants in this experiment (179 men and 640 women) were recruited in the same manner as in all the previous studies, but none had participated in previous experiments. Their mean reported total SAT score was 1161 (<em>SD</em> = 105). A substantial number of participants displayed denominator neglect in the marble task. Although a majority of participants (519—63.4%) picked the normatively correct small tray, 300 of the participants (36.6%) chose the large tray, thus displaying denominator neglect. The tendency to respond normatively in this task was, however, significantly associated with <strong data-auto="strong_text">cognitive ability</strong>. The mean SAT score of the participants choosing the small tray (1174, <em>SD</em> = 107) was significantly higher than the mean score of those choosing the large tray (1137, <em>SD</em> = 99), <em>t</em>(817) = 4.90, <em>p</em> &lt; .001, Cohen's <em>d</em> = 0.356. The point biserial correlation between tray choice and SAT total was .169 (<em>p</em> &lt; .001). Unlike the effects and <strong data-auto="strong_text">biases</strong> discussed in Experiments 1–7, the phenomenon of denominator neglect in this probabilistic choice paradigm was related to <strong data-auto="strong_text">cognitive ability</strong>.</p><p class="body-paragraph" data-auto="body_paragraph"><strong>Probabilistic Reasoning: Probability Matching Versus Maximizing</strong></p><p class="body-paragraph" data-auto="body_paragraph"><em>Problem 1</em></p><p class="body-paragraph" data-auto="body_paragraph">Modified from West and Stanovich (2003), this problem read as follows:
<blockquote>Consider the following hypothetical situation: A deck with 10 cards is randomly shuffled 10 separate times. The 10 cards are composed of 7 cards with the number “1” on the down side and 3 cards with the number “2” on the down side. Each time the 10 cards are reshuffled, your task is to predict the number on the down side of the top card. Imagine that you will receive $100 for each downside number you correctly predict, and that you want to earn as much money as possible. What would you predict after shuffle #1? (1 or 2); What would you predict after shuffle #2? (1 or 2);… What would you predict after shuffle #10? (1 or 2).</blockquote> Of the 819 participants who completed the marble problem (denominator neglect), 440 completed this probability matching Problem 1, and 379 completed probability matching Problem 2, to be described next.</p><p class="body-paragraph" data-auto="body_paragraph">For this problem, students who predicted any combination of 7 “1” cards and 3 “2” cards were classified as using the MATCH strategy (<em>n</em> = 184, 41.8%). Students who predicted “1” for each of the 10 cards were classified as using the maximizing (MAX) strategy (<em>n</em> = 105, 23.9%). Any other combination of card guesses was classified as the OTHER strategy (<em>n</em> = 151, 34.3%). The maximizing strategy is of course normative in this paradigm, but it was used by only a minority of participants.</p><p class="body-paragraph" data-auto="body_paragraph"><strong>Probabilistic Reasoning: Probability Matching Versus Maximizing</strong></p><p class="body-paragraph" data-auto="body_paragraph"><em>Problem 2</em></p><p class="body-paragraph" data-auto="body_paragraph">Adapted from West and Stanovich (2003; see also Gal &amp; Baron, 1996), this problem read as follows:
<blockquote>Consider the following situation: A die with 4 red faces and 2 green faces will be rolled 6 times. Before each roll you will be asked to predict which color (red or green) will show up once the die is rolled. Which color is most likely to show up after roll #1? (1 = red or 2 = green); Which color is most likely to show up after roll #2? (1 = red or 2 = green);… Which color is most likely to show up after roll #6? (1 = red or 2 = green).</blockquote> For this problem, students who chose any combination of 4 “red” faces and 2 “green” faces were classified as using the MATCH strategy (<em>n</em> = 173, 45.6%). Students who chose “red” for each of the six rolls were classified as using the MAX strategy (<em>n</em> = 130, 34.3%). Any other combination of color choices was classified as the OTHER strategy (<em>n</em> = 76, 20.1%).</p><p class="body-paragraph" data-auto="body_paragraph">Table 6 displays the mean SAT score for each of the response groups for probabilistic reasoning Problems 1 and 2. For Problem 1, there was a significant overall effect of group, <em>F</em>(2, 437) = 16.55, <em>MSE</em> = 10,126, <em>p</em> &lt; .001, ηp<sup>2</sup> = .070. The mean SAT score for the MAX group was significantly higher than the mean SAT score for both the MATCH group and the OTHER group. The point biserial correlation between responding normatively (MAX) versus nonnormatively (MATCH or OTHER) and SAT total score was .262 (<em>p</em> &lt; .001).<br/><br/> <img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/abfea9beee04bca2d0e05e86e182780e/5ebcb976/pdh/psp/psp-94-4-672-tbl6a.gif" alt="psp-94-4-672-tbl6a.gif" title="Means (Standard Deviations) of SAT Score for Participants Using the MAX, MATCH, and OTHER Strategies on the Two Probability Matching Problems in Experiment 8"/><em>Means (Standard Deviations) of SAT Score for Participants Using the MAX, MATCH, and OTHER Strategies on the Two Probability Matching Problems in Experiment 8</em></p><p class="body-paragraph" data-auto="body_paragraph">The results for probabilistic reasoning Problem 2 were exactly parallel. There was a significant overall effect of group, <em>F</em>(2, 376) = 14.85, <em>MSE</em> = 10,662, <em>p</em> &lt; .001, ηp<sup>2</sup> = .073. The mean SAT score for the MAX group was significantly higher than the mean SAT score for both the MATCH group and the OTHER group. The point biserial correlation between responding normatively (MAX) versus nonnormatively (MATCH or OTHER) and SAT total score was .270 (<em>p</em> &lt; .001). Like denominator neglect, the tendency to maximize predictive accuracy in this probabilistic reasoning task was related to <strong data-auto="strong_text">cognitive ability</strong>.</p><p class="body-paragraph" data-auto="body_paragraph"><strong>Belief Bias: Syllogisms</strong></p><p class="body-paragraph" data-auto="body_paragraph">Belief bias occurs when people have difficulty evaluating conclusions that conflict with what they think they know about the world (Evans, 2002; Evans, Barston, &amp; Pollard, 1983; Evans, Newstead, Allen, &amp; Pollard, 1994; Klauer, Musch, &amp; Naumer, 2000). It is most often assessed with syllogistic reasoning tasks in which the believability of the conclusion conflicts with logical validity.</p><p class="body-paragraph" data-auto="body_paragraph">Twenty-four syllogistic reasoning problems, largely drawn from Markovits and Nantel (1989), were completed by the participants. The 436 participants for this task (127 men and 309 women) were recruited in the same manner as in all the previous studies, but none had participated in previous experiments. Their mean reported total SAT score was 1174 (<em>SD</em> = 109). Eight of the problems—the inconsistent syllogisms—were worded such that the validity judgment was in conflict with the believability of the conclusion (e.g., All flowers have petals; roses have petals; therefore, roses are flowers–which is invalid). Eight of the problems—the consistent syllogisms—were worded such that the validity judgment was congruent with the believability of the conclusion (e.g., All fish can swim; tuna are fish; therefore, tuna can swim—which is valid). Eight of the problems—representing the neutral condition—involved imaginary content (e.g., All opprobines run on electricity; Jamtops run on electricity; therefore, Jamtops are opprobines–which is invalid) and were thus neither consistent nor inconsistent. Participants were instructed to judge the validity of the conclusion assuming that all of the premises were true.</p><p class="body-paragraph" data-auto="body_paragraph">A belief bias effect was demonstrated on the syllogistic reasoning task. The mean number of items answered correctly (out of 8) was 6.80 (<em>SD</em> = 1.27) in the consistent condition, 6.73 (<em>SD</em> = 1.38) in the neutral condition, and 5.11 (<em>SD</em> = 1.91) in the inconsistent condition. Participants answered significantly more consistent items than inconsistent items, <em>t</em>(435) = 18.06, <em>p</em> &lt; .001. <strong data-auto="strong_text">Cognitive ability</strong> was significantly correlated with the magnitude of belief bias (number of consistent items correct minus number of inconsistent items correct) displayed by each participant (r = −.28, <em>p</em> &lt; .001). Regarding the individual conditions separately, <strong data-auto="strong_text">cognitive ability</strong> correlated significantly (<em>p</em> &lt; .001) with the number of consistent items correct (<em>r</em> = .25), the number of neutral items correct (<em>r</em> = .39), and the number of inconsistent items correct (<em>r</em> = .45). <strong data-auto="strong_text">Cognitive ability</strong> correlated more highly with the inconsistent items than with the consistent items (test for difference between dependent correlations), <em>t</em>(433) = 4.07, <em>p</em> &lt; .001.</p><p class="body-paragraph" data-auto="body_paragraph"><strong>Belief Bias: Deductive Certainty of Modus Ponens</strong></p><p class="body-paragraph" data-auto="body_paragraph">The 381 participants for this task (94 men and 287 women) were recruited in the same manner as in all the previous studies, but none had participated in previous experiments. Their mean reported total SAT score was 1174 (<em>SD</em> = 109). This task was adapted from a study by George (1995). It is a deductive reasoning task that assesses whether participants recognize the deductive certainty of modus ponens. Participants read four arguments. Following is one example:
<blockquote>Premises: 1. If there is a postal strike, then unemployment will double. 2. There is a postal strike. Conclusion: 3. Unemployment will double.</blockquote> Participants responded on the following scale: <em>true</em> (7), <em>probably true</em> (6), <em>somewhat true</em> (5), <em>uncertain</em> (4), <em>somewhat false</em> (3), <em>probably false</em> (2), and <em>false</em> (1). Premise 1 in the other three arguments was as follows: “If the winter is harsh, then there will be a flu epidemic,” “If a car is a Honda, then it is expensive,” “If a person eats hamburgers, then he/she will get cancer.” The score on the task was the sum of the responses to all four items. Because the normatively correct answer on each item is “true,” normatively correct responding on the task should result in a score of 28.</p><p class="body-paragraph" data-auto="body_paragraph">Belief bias was shown on at least one of the modus ponens problems by 222 participants (they were less than certain that the syllogism was true on at least one problem). In contrast, 159 participants displayed no-belief bias on this task—they answered <em>true</em> to each of the four items. The mean SAT score of the no-belief bias group (1196, <em>SD</em> = 105) was significantly higher than the mean SAT score (1164, <em>SD</em> = 106) of the participants who displayed some degree of belief bias, <em>t</em>(379) = 2.91, <em>p</em> &lt; .01, Cohen's <em>d</em> = 0.302. A parallel, continuous analysis was conducted in which the score on each of four items (<em>true</em> = 7, <em>probably true</em> = 6, etc.) was summed to yield a total score on the modus ponens belief bias items. The correlation between this index and the SAT total score was .19 (<em>p</em> &lt; .001).</p><p class="body-paragraph" data-auto="body_paragraph"><strong>Informal Reasoning: Argument Evaluation Test</strong></p><p class="body-paragraph" data-auto="body_paragraph">The same participants who completed the previous task also were given the Argument Evaluation Test (AET; for details, see Stanovich &amp; West, 1997). The test consists of two parts. First, participants indicated their degree of agreement with a series of 23 target propositions (on topics such as gun control, taxes, university governance, crime, etc.) on a 4-point scale. Participants then evaluated arguments (which varied on an operationally defined measure of strength; see Stanovich &amp; West, 1997) relevant to these propositions. Individual differences in participants' reliance on objective argument quality were examined by running separate regression analyses on each participant's responses. Each participant's 23 argument evaluation responses were regressed simultaneously on both the 23 argument quality scores and the 23 prior opinion scores. The former beta weight was used as the primary indicator of the <strong data-auto="strong_text">ability</strong> to evaluate arguments independently of their prior opinion on the issue in question.</p><p class="body-paragraph" data-auto="body_paragraph">Performance on the AET was evaluated by examining the beta weight for argument quality for each participant. This score ranged from −.506 to .768 and displayed a mean of .296 (<em>SD</em> = .215). This beta weight was greater than zero for 90.9% of the sample. The beta weight for argument quality was significantly correlated with the SAT total score (<em>r</em> = .353, <em>p</em> &lt; .001), indicating that informal reasoning about argument quality was associated with <strong data-auto="strong_text">cognitive ability</strong>.</p><p class="body-paragraph" data-auto="body_paragraph"><strong>Four-Card Selection Task</strong></p><p class="body-paragraph" data-auto="body_paragraph">Participants who completed this task were 375 of the participants who completed the modus ponens task. Originally used by Wason (1966), the abstract version of the selection task has been studied extensively in the deductive reasoning literature (for detailed discussions of the enormous literature on the task, see Evans, Newstead, &amp; Byrne, 1993; Evans &amp; Over, 1996, 2004; Sperber, Cara, &amp; Girotto, 1995; Stanovich &amp; West, 1998a). The problem involves reasoning about the falsifiability of an “if P then Q” type of rule. We used a version with features that facilitated performance: “violation” instructions, requiring justifications for each of the choices, and using a form of the rule that discourages a biconditional interpretation (see Platt &amp; Griggs, 1993, 1995).</p><p class="body-paragraph" data-auto="body_paragraph">The correct response is to choose the P and not-Q cards. We specifically examined the common response patterns that have been discussed in the literature: P-only, PQ, all of the cards, and PQ not-Q. All remaining response patterns were classified as Other. We also constructed the “logic index” employed by Pollard and Evans (1987). It is formed by subtracting the number of incorrect responses (not-P and Q) from the number of correct responses (P and not-Q).</p><p class="body-paragraph" data-auto="body_paragraph">The major response patterns on the four-card selection task and the mean SAT score associated with that pattern are displayed in Table 7. Because this version of the task contained several features that have been found to facilitate performance in past studies (Platt &amp; Griggs, 1993, 1995), the solution rate (30.9%) was substantially higher than that usually obtained with the abstract selection task (often 10% or less). <strong data-auto="strong_text">Cognitive ability</strong> was associated with the response given to this version of selection task. In a one-way ANOVA, there was a significant overall effect of group, <em>F</em>(5, 369) = 8.22, <em>MSE</em> = 10,213, <em>p</em> &lt; .001, ηp<sup>2</sup> = .100. Partitioning the sample somewhat differently, we found that the mean SAT score (1214, <em>SD</em> = 96) of the group answering correctly was significantly higher than the mean SAT score (1163, <em>SD</em> = 106) of those giving an incorrect answer, <em>t</em>(373) = 4.40, <em>p</em> &lt; .001, Cohen's <em>d</em> = 0.493. Finally, there was a statistically significant correlation between the logic index score for the task and the SAT total score (<em>r</em> = .292, <em>p</em> &lt; .001). Thus, all of the analyses of this task consistently pointed to an association between <strong data-auto="strong_text">cognitive ability</strong> and selection task performance.<br/><br/> <img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/2bd8b204ff9bc54bd7c5c11434a39576/5ebcb976/pdh/psp/psp-94-4-672-tbl7a.gif" alt="psp-94-4-672-tbl7a.gif" title="Means (Standard Deviations) of Total SAT Score for Each of the Major Response Patterns in the Four-Card Selection Task"/><em>Means (Standard Deviations) of Total SAT Score for Each of the Major Response Patterns in the Four-Card Selection Task</em></p> 