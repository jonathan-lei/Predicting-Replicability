<h3>Method</h3><br/> <h4>Participants</h4><p class="body-paragraph" data-auto="body_paragraph">A total of 72 participants were recruited from the University of Maryland community with advertisements placed throughout the campus. The sample consisted of 38 men and 34 women, ranging in age from 18 to 34 years (<em>M</em> = 21.6, <em>SD</em> = 3.9). Fifty-six percent described themselves as White, 18% as Black or African American, 17% as Asian or Southeast Asian, and 4% as Hispanic or Latino; the remaining 6% marked “Other” or chose not to respond to the question. They were paid $7 for their time. In addition, participants could earn a bonus based on their winnings in the games. On average, people received an extra $5, but a few won nothing and one individual earned an extra $12.</p> <h4>Materials</h4><p class="body-paragraph" data-auto="body_paragraph"><strong>The ART</strong></p><p class="body-paragraph" data-auto="body_paragraph">In each of the four tournaments participants had <em>H</em> = 30 rounds during which they fished in a pond similar to the one shown in Figure 1. At the beginning of each round the pond had 1 blue fish and <em>n –</em> 1 red fish. Below the pond were two buttons and an information panel. One button was labeled “Go Fish.” Pressing it caused the rod on the left of the screen to cast a line into the pond and hook a fish. Each fish was equally likely to be caught on a given cast. If a red fish was caught, then <em>5¢</em> was placed into the “Trip Bank” shown on the information panel. What happened next depended on the release law. If the law was catch `n' keep, then the red fish was placed in the cooler on the right of the screen, reducing the total number of red fish in the pond by one. If the law was catch `n' release, then the red fish was placed back into the pond. Either way, the computerized fish swam around the pond and participants had another opportunity to cast the line into the pond for that round. However, if a blue fish was caught, then the round ended and participants lost their accumulated money in the “Trip Bank.” When participants decided to stop fishing, they pressed the “Collect” button to transfer the money to the “Tournament Bank” on the information panel and then began a new round.</p><p class="body-paragraph" data-auto="body_paragraph">In addition to the two release laws, there were two types of weather conditions. If the weather was sunny—as indicated by the weather forecast in the bottom right—the pond was clear and participants could see how many fish were in it at all times. Additionally, the information panel listed how many red and blue fish were in the pond before each cast. However, if the weather was cloudy, then the pond was murky, concealing the number of fish in the pond and the information panel was left blank. Combining the two release laws with the two weather forecasts produced four different fishing tournaments (conditions). Participants completed all four tournaments.</p><p class="body-paragraph" data-auto="body_paragraph"><strong>Drug and alcohol questionnaire</strong></p><p class="body-paragraph" data-auto="body_paragraph">As a measure of risky illegal/legal drug use, participants reported with yes/no responses the number of drug categories ever tried. The 11 different drug categories were cannabis, alcohol, cocaine, MDM (ecstasy), stimulants (e.g., speed), sedatives/hypnotics, opiates, hallucinogens, PCP, inhalants, and nicotine. The sum of the number of categories tried (polydrug) is a validated measure of risky drug use (see Babor et al., 1992; Grant, Contoreggi, &amp; London, 2000). After each yes/no question, participants were also asked to report about how often they used the drug at the time in their life when they used it the most frequently (i.e., <em>never, one time, monthly or less, 2 to 4 times a month, 2 to 3 times a week</em>, or <em>4 or more times a week</em>). Weighting the categories that participants reported trying with the frequency rank and summing created the measure identified as <em>weighted polydrug</em>.</p><p class="body-paragraph" data-auto="body_paragraph"><strong>Domain-Specific <strong data-auto="strong_text">Risk</strong>-<strong data-auto="strong_text">Taking</strong> (DOSPERT) Scale</strong></p><p class="body-paragraph" data-auto="body_paragraph">Participants also completed the DOSPERT Scale (Weber et al., 2002), which contains 40 items that assess the likelihood of engaging in risky behavior in six domains: ethics, investment, gambling, health/safety, recreational, and social. Two separate variants of the scale also assess the perception of the magnitude of the <strong data-auto="strong_text">risk</strong> for and expected benefit from each of the 40 <strong data-auto="strong_text">risks</strong>. The DOSPERT has also had success in identifying real-world <strong data-auto="strong_text">risk</strong> takers (Hanoch, Johnson, &amp; Wilke, 2006).</p> <h4>Design and Procedure</h4><p class="body-paragraph" data-auto="body_paragraph">The study used a 2 (release law) × 2 (weather) within-subjects design. Participants fished in all four tournaments (conditions) and completed the drug and alcohol questionnaire along with the DOSPERT Scale. Participants had 30 rounds per tournament to cast for as many red fish as they chose, earning 5¢ per red fish caught. Intertask comparisons were facilitated by setting the ART parameter settings to be similar to those used in the BART. In the BART (a nonstationary environment), the total number of possible choice trials (pumps) is typically set at <em>n</em> = 128 (Lejuez et al., 2002). If the goal of participants is to maximize expected value and they have full knowledge of the structure of the task, then the strategy that maximizes earnings is for participants to choose the play option on approximately 64 of the choice trials. This setting has been found to be the best for distinguishing between real-world <strong data-auto="strong_text">risk</strong> seekers and <strong data-auto="strong_text">risk</strong> avoiders (Lejuez et al., 2002). Consequently, in the catch `n' keep conditions there were <em>n</em> = 128 total number of fish or possible choice trials. Calibrating the catch `n' release conditions in the ART so that choosing play 64 times per round was the maximizing strategy (assuming the same conditions as above) was done by setting the number of fish at <em>n</em> = 65 fish (see Equation 2 with γ<sup>+</sup> = 1). Thus, if participants had a precise understanding of all four tasks and sought to maximize expected value, they should make an equal number of casts in all four tournaments.</p><p class="body-paragraph" data-auto="body_paragraph">The order in which participants completed each tournament and the <strong data-auto="strong_text">risk</strong> questionnaires was counterbalanced. All eight tasks were programmed using Sun Microsystem's Java language and are available upon request. The entire experiment was administered on PC computers in separate sound-attenuated laboratory cubicles.</p><p class="body-paragraph" data-auto="body_paragraph">After reading and signing the informed consent form, participants read an introductory set of instructions on the computer. They were told that they would be playing four different fishing tournaments with different rules and conditions. The instructions described the two different release laws and the two different weather conditions they would experience. Participants were also informed that between each fishing tournament they would fill out questionnaires assessing their own risky behavior. No further instructions were given about the stochastic structure of the tasks.</p><p class="body-paragraph" data-auto="body_paragraph">Next, the participants completed four practice games, one for each tournament. During the practice games participants were able to select how many fish they would like in the pond to practice with (1 to 360). This manipulation was done to demonstrate that the ponds in each of the <strong data-auto="strong_text">experimental</strong> conditions could have any number of fish so as to minimize knowledge transfer from one tournament to the next. During the practice round participants played each condition for two rounds, during which they cast for red fish as many times as they chose to.</p><p class="body-paragraph" data-auto="body_paragraph">After completing the four practice games, they began the <strong data-auto="strong_text">experimental</strong> session, alternating between the four questionnaires and the four tournaments. They started with a questionnaire. Before each tournament, participants were briefly reminded of the rules governing the pond they were about to visit. After completing all of the tournaments, they completed a set of questions regarding the strategy they used to fish in the tournaments. At the conclusion of the session, the computer produced four tables showing how much money participants earned on each round during the four tournaments. A round from each tournament was then chosen randomly using a bingo basket (four rounds total), and participants were paid based on their performance during these rounds.</p> 