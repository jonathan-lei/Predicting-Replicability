<h3>Experiment 1</h3><br/><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">In the first
experiment, participants were presented with green pictures superimposed onto red
pictures. </button><button class="sentence">Eye movements were recorded while participants named the green picture of
the picture–picture stimuli (presented on the left side of a computer
screen) and manually responded by pressing a left or right button in response to the
left- or right-pointing arrows (&lt; or &gt;, presented on the right side of
the screen). </button><button class="sentence">For example, they said “hammer” in response to a
pictured hammer in green color, while trying to ignore a pictured chisel in red (the
semantically related condition) or a pictured sandal in red (the semantically
unrelated condition). </button><button class="sentence">Or they said “circle” in response to a
pictured circle in green, while trying to ignore a pictured circus in red (the
phonologically related condition) or a pictured table in red (the phonologically
unrelated condition). </button><button class="sentence">To minimize the chance that participants would identify the
direction of the arrows by their peripheral vision, the arrows were flanked by two
Xs on each side, yielding <em>XX &lt;XX</em> and <em>XX&gt;
XX</em> as stimuli.</button></p> <h4>Method</h4><p class="body-paragraph" data-auto="body_paragraph"><strong>Participants</strong></p><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">The
experiment was carried out with a group of 24 paid participants from the
pool at the Max Planck Institute for Psycholinguistics in Nijmegen. </button><button class="sentence">All
participants were young adults who were native speakers of Dutch. </button><button class="sentence">None of
the participants took part in one of the other experiments.</button></p><p class="body-paragraph" data-auto="body_paragraph"><strong>Materials and design</strong></p><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">From the
picture gallery available at the Max Planck Institute, 40 pictured objects
were selected. </button><button class="sentence">All pictures had disyllabic names. </button><button class="sentence">The pictures were chosen
such that 10 pairs of pictures had names that were semantically related and
the 10 remaining pairs had names that were phonologically related. </button><button class="sentence">The
pictures with phonologically related names shared the first syllable. </button><button class="sentence">The
unrelated conditions were created by recombining the pictures such that each
semantically related picture also served as a semantically unrelated picture
and each phonologically related picture also served as a phonologically
unrelated picture. </button><button class="sentence">The Appendix lists the materials. </button><button class="sentence">The pictures were line
drawings on a black background. </button><button class="sentence">They were digitized and scaled to fit into a
virtual frame of 10 cm × 10 cm. On average, the pictures subtended
8.7° horizontally and 8.7° vertically at a viewing
distance of 66 cm (roughly the distance between the participant and the
screen). </button><button class="sentence">The arrows were presented in 28-point uppercase Arial font,
subtending 3.5° horizontally and 0.9° vertically. </button><button class="sentence">The
horizontal distance between the middle of the picture–picture
stimuli and the arrow stimuli was 15.2°.</button></p><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">There were
two independent variables: type and relation. </button><button class="sentence">The variable type indicated
whether the pictures were from the semantic or the phonological sets. </button><button class="sentence">The
variable relation indicated whether the paired pictures were related or
unrelated. </button><button class="sentence">Both variables were tested within participants. </button><button class="sentence">Relation was
tested within items and type was tested between items. </button><button class="sentence">A participant
received 20 picture–picture pairings in each of the four
distractor conditions, yielding 80 picture–picture stimuli in
total. </button><button class="sentence">Each picture pair was presented twice, yielding 160 trials per
participant in total. </button><button class="sentence">The order of presenting the stimuli across trials was
random, except that repetitions of pictures and words on successive trials
were not permitted.</button></p><p class="body-paragraph" data-auto="body_paragraph"><strong>Apparatus</strong></p><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">Materials
were presented on a 39-cm ViewSonic 17PS screen. </button><button class="sentence">Eye movements were measured
using an SMI EyeLink-HiSpeed 2D headband-mounted eye-tracking system
(SensoMotoric Instruments GmbH, Teltow, Germany). </button><button class="sentence">The eye tracker was
controlled by a Pentium 90 MHz computer. </button><button class="sentence">The experiment was run under the
Nijmegen Experiment Setup (NESU) with a NESU button box on a Pentium 400 MHz
computer. </button><button class="sentence">The participants' utterances were recorded over a Sennheiser ME400
microphone to a SONY DTC55 digital audio tape (DAT) recorder. </button><button class="sentence">Vocal response
latencies were measured using an electronic voice key.</button></p><p class="body-paragraph" data-auto="body_paragraph"><strong>Procedure</strong></p><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">The
participants were tested individually. </button><button class="sentence">They were seated in front of the
computer monitor, a panel with a left and a right push button, and the
microphone. </button><button class="sentence">The distance between participant and screen was approximately 66
cm. Participants were given written instructions telling them how their eyes
would be monitored and what the task was. </button><button class="sentence">The experimenter also orally
described the eye-tracking equipment and restated the instructions. </button><button class="sentence">The
participants were told that they had to name the green picture of
picture–picture stimuli presented on the left side of a computer
screen and manually respond by pressing a left or right button in response
to the arrows presented on the right side of the screen. </button><button class="sentence">To familiarize them
with the pictures, the participants received a booklet showing them all
pictures used in the experiment together with the expected names.</button></p><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">When a
participant had read the instructions and studied the picture booklet, the
headband of the eye-tracking system was placed on the participant's head,
and the system was calibrated and validated. </button><button class="sentence">For pupil-to-gaze calibration,
a grid of 3 × 3 positions had been defined. </button><button class="sentence">During a calibration
trial, a fixation target appeared once, in random order, in each of these
positions for one second. </button><button class="sentence">Participants were asked to fixate upon each target
until the next target appeared. </button><button class="sentence">After the calibration trial, the estimated
positions of the participant's fixations and the distances from the fixation
targets were displayed to the experimenter. </button><button class="sentence">Calibration was considered
adequate if there was at least one fixation within 1.5° of each
fixation target. </button><button class="sentence">When calibration was inadequate, the procedure was
repeated, sometimes after adjusting the eye cameras. </button><button class="sentence">Successful calibration
was followed by a pupil-to-gaze validation trial. </button><button class="sentence">For the participants, this
trial did not differ from the calibration trial, but the data collected
during the validation trial were used to estimate the participants' gaze
positions, and the error (i.e., the distance between the estimated gaze
position and the target position) was measured. </button><button class="sentence">Validation was considered
completed if the average error was less than 1.0° and the worst
error less than 1.5°. </button><button class="sentence">Depending on the result of the validation
trial, the calibration and validation trials were repeated or testing began.</button></p><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">After
successful calibration and validation, a block of 40 practice trials was
administered, in which each picture was shown and named once. </button><button class="sentence">This was
followed by the 160 experimental trials. </button><button class="sentence">The structure of a trial was as
follows. </button><button class="sentence">A trial started by the simultaneous presentation of the left
picture–picture and right arrow stimuli. </button><button class="sentence">The stimuli remained on
the screen until the participant pushed the button in response to the arrow.
The arrows were presented in white. </button><button class="sentence">The colored pictures and the arrows were
presented on a black background. </button><button class="sentence">Before the start of the next trial there
was a blank interval of 1.5 sec. </button><button class="sentence">The position of the left and right eyes was
determined every 4 ms. Drift correction occurred automatically after every 8
trials.</button></p><p class="body-paragraph" data-auto="body_paragraph"><strong>Analyses</strong></p><p class="body-paragraph" data-auto="body_paragraph"><button class="sentence">A naming
response was considered to be invalid when it included a speech error, when
a wrong word was produced, or when the voice key was triggered incorrectly.
Error trials were discarded from the analyses of the naming latencies and
gaze shift latencies. </button><button class="sentence">To analyze the speakers' gaze shifts, their eye
fixations were classified as falling within or on the outer contours of the
left stimulus or elsewhere. </button><button class="sentence">Although viewing was binocular and the positions
of both eyes were tracked, only the position of the right eye was analyzed.
Gaze shift latency was defined as the time interval between the beginning of
the first fixation on the left stimulus and the end of the last fixation
before the first shift of gaze was initiated to the right arrow. </button><button class="sentence">The vocal
response latencies, gaze shift latencies, and errors were submitted to
analyses of variance. </button><button class="sentence">The analyses were performed both by participants
(<em>F</em>1) and
by items (<em>F</em>2).
Faster responding in the related than unrelated condition will be called
descriptively <em>facilitation</em> and slower responding will be
called <em>interference</em>.</button></p> 