<h3>Experiment 1</h3><br/><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">In the first
experiment, participants were presented with green pictures superimposed onto red
pictures. </span><span class="sentence">Eye movements were recorded while participants named the green picture of
the picture–picture stimuli (presented on the left side of a computer
screen) and manually responded by pressing a left or right button in response to the
left- or right-pointing arrows (&lt; or &gt;, presented on the right side of
the screen). </span><span class="sentence">For example, they said “hammer” in response to a
pictured hammer in green color, while trying to ignore a pictured chisel in red (the
semantically related condition) or a pictured sandal in red (the semantically
unrelated condition). </span><span class="sentence">Or they said “circle” in response to a
pictured circle in green, while trying to ignore a pictured circus in red (the
phonologically related condition) or a pictured table in red (the phonologically
unrelated condition). </span><span class="sentence">To minimize the chance that participants would identify the
direction of the arrows by their peripheral vision, the arrows were flanked by two
Xs on each side, yielding <em>XX &lt;XX</em> and <em>XX&gt;
XX</em> as stimuli.</span></p> <h4>Method</h4><p class="body-paragraph" data-auto="body_paragraph"><strong>Participants</strong></p><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">The
experiment was carried out with a group of 24 paid participants from the
pool at the Max Planck Institute for Psycholinguistics in Nijmegen. </span><span class="sentence">All
participants were young adults who were native speakers of Dutch. </span><span class="sentence">None of
the participants took part in one of the other experiments.</span></p><p class="body-paragraph" data-auto="body_paragraph"><strong>Materials and design</strong></p><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">From the
picture gallery available at the Max Planck Institute, 40 pictured objects
were selected. </span><span class="sentence">All pictures had disyllabic names. </span><span class="sentence">The pictures were chosen
such that 10 pairs of pictures had names that were semantically related and
the 10 remaining pairs had names that were phonologically related. </span><span class="sentence">The
pictures with phonologically related names shared the first syllable. </span><span class="sentence">The
unrelated conditions were created by recombining the pictures such that each
semantically related picture also served as a semantically unrelated picture
and each phonologically related picture also served as a phonologically
unrelated picture. </span><span class="sentence">The Appendix lists the materials. </span><span class="sentence">The pictures were line
drawings on a black background. </span><span class="sentence">They were digitized and scaled to fit into a
virtual frame of 10 cm × 10 cm. </span><span class="sentence">On average, the pictures subtended
8.7° horizontally and 8.7° vertically at a viewing
distance of 66 cm (roughly the distance between the participant and the
screen). </span><span class="sentence">The arrows were presented in 28-point uppercase Arial font,
subtending 3.5° horizontally and 0.9° vertically. </span><span class="sentence">The
horizontal distance between the middle of the picture–picture
stimuli and the arrow stimuli was 15.2°.</span></p><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">There were
two independent variables: type and relation. </span><span class="sentence">The variable type indicated
whether the pictures were from the semantic or the phonological sets. </span><span class="sentence">The
variable relation indicated whether the paired pictures were related or
unrelated. </span><span class="sentence">Both variables were tested within participants. </span><span class="sentence">Relation was
tested within items and type was tested between items. </span><span class="sentence">A participant
received 20 picture–picture pairings in each of the four
distractor conditions, yielding 80 picture–picture stimuli in
total. </span><span class="sentence">Each picture pair was presented twice, yielding 160 trials per
participant in total. </span><span class="sentence">The order of presenting the stimuli across trials was
random, except that repetitions of pictures and words on successive trials
were not permitted.</span></p><p class="body-paragraph" data-auto="body_paragraph"><strong>Apparatus</strong></p><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">Materials
were presented on a 39-cm ViewSonic 17PS screen. </span><span class="sentence">Eye movements were measured
using an SMI EyeLink-HiSpeed 2D headband-mounted eye-tracking system
(SensoMotoric Instruments GmbH, Teltow, Germany). </span><span class="sentence">The eye tracker was
controlled by a Pentium 90 MHz computer. </span><span class="sentence">The experiment was run under the
Nijmegen Experiment Setup (NESU) with a NESU button box on a Pentium 400 MHz
computer. </span><span class="sentence">The participants' utterances were recorded over a Sennheiser ME400
microphone to a SONY DTC55 digital audio tape (DAT) recorder. </span><span class="sentence">Vocal response
latencies were measured using an electronic voice key.</span></p><p class="body-paragraph" data-auto="body_paragraph"><strong>Procedure</strong></p><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">The
participants were tested individually. </span><span class="sentence">They were seated in front of the
computer monitor, a panel with a left and a right push button, and the
microphone. </span><span class="sentence">The distance between participant and screen was approximately 66
cm. </span><span class="sentence">Participants were given written instructions telling them how their eyes
would be monitored and what the task was. </span><span class="sentence">The experimenter also orally
described the eye-tracking equipment and restated the instructions. </span><span class="sentence">The
participants were told that they had to name the green picture of
picture–picture stimuli presented on the left side of a computer
screen and manually respond by pressing a left or right button in response
to the arrows presented on the right side of the screen. </span><span class="sentence">To familiarize them
with the pictures, the participants received a booklet showing them all
pictures used in the experiment together with the expected names.</span></p><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">When a
participant had read the instructions and studied the picture booklet, the
headband of the eye-tracking system was placed on the participant's head,
and the system was calibrated and validated. </span><span class="sentence">For pupil-to-gaze calibration,
a grid of 3 × 3 positions had been defined. </span><span class="sentence">During a calibration
trial, a fixation target appeared once, in random order, in each of these
positions for one second. </span><span class="sentence">Participants were asked to fixate upon each target
until the next target appeared. </span><span class="sentence">After the calibration trial, the estimated
positions of the participant's fixations and the distances from the fixation
targets were displayed to the experimenter. </span><span class="sentence">Calibration was considered
adequate if there was at least one fixation within 1.5° of each
fixation target. </span><span class="sentence">When calibration was inadequate, the procedure was
repeated, sometimes after adjusting the eye cameras. </span><span class="sentence">Successful calibration
was followed by a pupil-to-gaze validation trial. </span><span class="sentence">For the participants, this
trial did not differ from the calibration trial, but the data collected
during the validation trial were used to estimate the participants' gaze
positions, and the error (i.e., the distance between the estimated gaze
position and the target position) was measured. </span><span class="sentence">Validation was considered
completed if the average error was less than 1.0° and the worst
error less than 1.5°. </span><span class="sentence">Depending on the result of the validation
trial, the calibration and validation trials were repeated or testing began.</span></p><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">After
successful calibration and validation, a block of 40 practice trials was
administered, in which each picture was shown and named once. </span><span class="sentence">This was
followed by the 160 experimental trials. </span><span class="sentence">The structure of a trial was as
follows. </span><span class="sentence">A trial started by the simultaneous presentation of the left
picture–picture and right arrow stimuli. </span><span class="sentence">The stimuli remained on
the screen until the participant pushed the button in response to the arrow.
The arrows were presented in white. </span><span class="sentence">The colored pictures and the arrows were
presented on a black background. </span><span class="sentence">Before the start of the next trial there
was a blank interval of 1.5 sec. </span><span class="sentence">The position of the left and right eyes was
determined every 4 ms. Drift correction occurred automatically after every 8
trials.</span></p><p class="body-paragraph" data-auto="body_paragraph"><strong>Analyses</strong></p><p class="body-paragraph" data-auto="body_paragraph"><span class="sentence">A naming
response was considered to be invalid when it included a speech error, when
a wrong word was produced, or when the voice key was triggered incorrectly.
Error trials were discarded from the analyses of the naming latencies and
gaze shift latencies. </span><span class="sentence">To analyze the speakers' gaze shifts, their eye
fixations were classified as falling within or on the outer contours of the
left stimulus or elsewhere. </span><span class="sentence">Although viewing was binocular and the positions
of both eyes were tracked, only the position of the right eye was analyzed.
Gaze shift latency was defined as the time interval between the beginning of
the first fixation on the left stimulus and the end of the last fixation
before the first shift of gaze was initiated to the right arrow. </span><span class="sentence">The vocal
response latencies, gaze shift latencies, and errors were submitted to
analyses of variance. </span><span class="sentence">The analyses were performed both by participants
(<em>F</em>1) and
by items (<em>F</em>2).
Faster responding in the related than unrelated condition will be called
descriptively <em>facilitation</em> and slower responding will be
called <em>interference</em>.</span></p> 