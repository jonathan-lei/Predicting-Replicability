<div class="sectionInfo"><h2 class="sectionHeading">METHOD</h2></div><div class="head-b"><h3>Participants</h3></div><p><span class="sentence">The 14 participants (11 females and 3 males; ages 17–39 years, <i>M</i> = 25.7) were all right-handed and had either normal or corrected-to-normal vision.</span></p><div class="head-b"><h3>Apparatus</h3></div><p><span class="sentence">The experiment was controlled by a 1.5-GHz Pentium IV computer. </span><span class="sentence">Stimuli were presented on a Trinitron Multiscan G240 monitor (17 in.), using a screen resolution of 600 × 800 pixels. </span><span class="sentence">The display height was adjusted for each participant by setting the height of the chair he or she sat on. </span><span class="sentence">Eye movements were recorded using a head-mounted eyetracker (SMI Eyelink V2.04; SensoMotoric Instruments GmbH, Berlin, Germany) with a sampling rate of 250 Hz. </span><span class="sentence">Responses were registered using a button box.</span></p><div class="head-b"><h3>Procedure</h3></div><p><span class="sentence">The display sequence is depicted in <span class="figure refFigure figuresContent" id="ref-figure1-j1467-9280200802044x">Figure 1a</span>. </span><span class="sentence">Each trial started with a black fixation point, shown against a white background screen. </span><span class="sentence">The duration of this display was unlimited. </span><span class="sentence">When ready, the participant pressed a button to remove the fixation point, and the instructions regarding what to search for were displayed for 2,000 ms (black text on a white background). </span><span class="sentence">A second fixation point (600 ms) preceded the stimulus display, which remained present until the participant responded. </span><span class="sentence">Participants were instructed to look for and to fixate the target; once they were sure they had found the target, they were to press a button to end the trial. </span><span class="sentence">The speed of the button-press response was not emphasized. </span><span class="sentence">The target was present in all trials. </span><span class="sentence">Presentation of stimuli was self-paced, and subjects were allowed to take an unlimited number of breaks.</span></p><div class="figure" id="figure1-j.1467-9280.2008.02044.x"><div class="holder"><img alt="&#10;                        figure&#10;                    " src="/paper_data/img/10.1111_j.1467-9280.2008.02044.x-fig1.gif"/><div class="caption"><p><span class="captionLabel">Fig. 1.</span> Illustration of the display sequence (a) and of an object in its prototypical and nonprototypical views (b). The example sequence shown here is from the name condition.</p></div></div></div><p><span class="sentence">The stimuli were black-and-white photographs of real objects (see <span class="figure refFigure figuresContent" id="ref-figure1-j1467-9280200802044x">Fig. 1b</span>). </span><span class="sentence">On any trial, all the stimuli were depicted in either a prototypical or a nonprototypical view (view was randomized across trials). </span><span class="sentence">When an object was depicted in a prototypical view, all its main features were visible, and the object was aligned for action. </span><span class="sentence">In the nonprototypical view, the object was rotated away from its usual view, and it was not oriented for a right-hand action; typically, the graspable part of the object was positioned toward the nondominant (left) hand (for our right-handed participants).</span></p><p><span class="sentence">Each photograph was inscribed into an area measuring 100 × 100 pixels (4.6° × 4.6° at a viewing distance of 60 cm), and the relative size of the objects was taken into account (e.g., a bicycle was bigger than a pen). </span><span class="sentence">Within each display, eight stimuli were presented in a circle with a radius of 170 pixels (7.4°); the two middle objects were placed at eye level, in order to have the three upper objects falling in the upper visual field and the three lower objects falling in the lower visual field. </span><span class="sentence">The target's position was randomized across trials. </span><span class="sentence">In the analyses, we excluded trials in which the target was one of the two middle objects, considering only stimuli in the upper and lower visual fields.</span></p><p><span class="sentence">There were two instruction conditions, presented in two separate blocks of 240 trials each, and block order was randomized across participants. </span><span class="sentence">In the <i>name</i> condition, the participants were given the names of the objects they had to look at (e.g., “scissors”); in the <i>action</i> condition, each target was defined by the associated action (e.g., “cut paper”). </span><span class="sentence">Thus, the target was ambiguously specified in the action condition, because there are typically multiple objects consistent with a given action. </span><span class="sentence">However, within a search display, there was only one object consistent with the instructions given (i.e., only one object with the name given in name search and only one object consistent with the action given in action search). </span><span class="sentence">We used a set of 60 familiar objects; 20 that could be defined either by a name or by a specific action were used as targets, and the remaining 40 were always used as distractors.</span></p>